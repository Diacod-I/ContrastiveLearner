{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pickle\nimport os\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom tqdm import tqdm\nimport json\nimport numpy as np\nimport time\nimport copy\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision import datasets, models, transforms\nfrom torch.optim import lr_scheduler\nimport cv2\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Counter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\ndef compute_AUCs(gt, pred):\n    gt_np = gt.cpu().numpy()\n    pred_np = pred.cpu().numpy()\n    return roc_auc_score(gt_np[:,0], pred_np[:,0])\n\ndef cross_auc(R_a_0, R_b_1): \n    scores = np.array(list(R_a_0.cpu().numpy()) + list(R_b_1.cpu().numpy()))\n    y_true = np.zeros(len(R_a_0)+len(R_b_1))\n    y_true[0:len(R_a_0)] = 1 # Pr[ LEFT > RIGHT]; Y = 1 is the left (A0)\n    return roc_auc_score(y_true, scores)\n\n\ndef group_auc(labels, outputs, groups):\n    groups = {}\n    for i in range(4):\n        groups[\"group\"+str(i)+\"p\"]=[]\n        groups[\"group\"+str(i)+\"n\"]=[]\n        \n    for i in range(len(labels)):\n        if groups[i] == 0:\n            if labels[i][0] == 1:\n                group0p.append(i)\n            if labels[i][0] == 0:\n                group0n.append(i)\n        if groups[i] == 1:\n            if labels[i][0] == 1:\n                group1p.append(i)\n            if labels[i][0] == 0:\n                group1n.append(i)\n        if groups[i] == 2:\n            if labels[i][0] == 1:\n                group2p.append(i)\n            if labels[i][0] == 0:\n                group2n.append(i)       \n        if groups[i] == 3:\n            if labels[i][0] == 1:\n                group3p.append(i)\n            if labels[i][0] == 0:\n                group3n.append(i)   \n                \n    groupp = group0p+group1p+group2p+group3p  \n    groupn = group0n+group1n+group2n+group3n\n    outputs_ = outputs.clone().detach().cpu()\n    \n    try:\n        AUC = cross_auc(torch.index_select(outputs_,0,torch.tensor(groupp)), torch.index_select(outputs_,0,torch.tensor(groupn)))\n    except:\n        AUC = 1\n    \n    Cross_auc = {}\n    total_squares = 4\n    for n in range(total_squares):\n        try:\n            Cross_auc['A' + str(n) + str(n)] = cross_auc(torch.index_select(outputs_,0,torch.tensor(groups[\"group\"+str(n)+\"p\"])), torch.index_select(outputs_,0,torch.tensor(\"group\"+str(n)+\"n\")))\n        except:\n            Cross_auc['A' + str(n) + str(n)] = 1\n        try:\n            Cross_auc['A' + str(n) + 'a'] = cross_auc(torch.index_select(outputs_,0,torch.tensor(groups[\"group\"+str(n)+\"p\"])), torch.index_select(outputs_,0,torch.tensor(\"group\"+str(n)+\"n\")))\n        except:\n            Cross_auc['A' + str(n) + 'a'] = 1\n        try:\n            Cross_auc['A' + 'a' + str(n)] = cross_auc(torch.index_select(outputs_,0,torch.tensor(groups[\"group\"+str(n)+\"p\"])), torch.index_select(outputs_,0,torch.tensor(\"group\"+str(n)+\"n\")))\n        except:\n            Cross_auc['A' + 'a' + str(n)] = 1\n  \n    group_num = [len(group0p),len(group0n),len(group1p),len(group1n),len(group2p),len(group2n),len(group3p),len(group3n)]\n    \n    return Cross_auc\ngroup_num\n\ndef criterion(outputs, labels, groups):\n    \n    group0p = []\n    group0n = []\n    group1p = []\n    group1n = []\n    group2p = []\n    group2n = []\n    group3p = []\n    group3n = []\n\n    for i in range(len(labels)):\n        if groups[i] == 0:\n            if labels[i][0] == 1:\n                group0p.append(i)\n            if labels[i][0] == 0:\n                group0n.append(i)\n        if groups[i] == 1:\n            if labels[i][0] == 1:\n                group1p.append(i)\n            if labels[i][0] == 0:\n                group1n.append(i)\n        if groups[i] == 2:\n            if labels[i][0] == 1:\n                group2p.append(i)\n            if labels[i][0] == 0:\n                group2n.append(i)       \n        if groups[i] == 3:\n            if labels[i][0] == 1:\n                group3p.append(i)\n            if labels[i][0] == 0:\n                group3n.append(i)   \n                \n    groupp = group0p+group1p+group2p+group3p  \n    groupn = group0n+group1n+group2n+group3n\n    outputs_ = outputs.clone().detach().cpu()\n    \n    try:\n        AUC = cross_auc(torch.index_select(outputs_,0,torch.tensor(groupp)), torch.index_select(outputs_,0,torch.tensor(groupn)))\n    except:\n        AUC = 1\n    try:\n        AUC0a = cross_auc(torch.index_select(outputs_,0,torch.tensor(group0p)), torch.index_select(outputs_,0,torch.tensor(groupn)))\n    except:\n        AUC0a = 1.1\n    try:\n        AUC1a = cross_auc(torch.index_select(outputs_,0,torch.tensor(group1p)), torch.index_select(outputs_,0,torch.tensor(groupn)))\n    except:\n        AUC1a = 1.1\n    try:\n        AUC2a = cross_auc(torch.index_select(outputs_,0,torch.tensor(group2p)), torch.index_select(outputs_,0,torch.tensor(groupn)))\n    except:\n        AUC2a = 1.1\n    try:\n        AUC3a = cross_auc(torch.index_select(outputs_,0,torch.tensor(group3p)), torch.index_select(outputs_,0,torch.tensor(groupn)))\n    except:\n        AUC3a = 1.1\n\n#     if AUC ==1 and AUC0a == 1 and AUC1a == 1:\n#         print('three auc are', AUC)\n    loss = nn.MarginRankingLoss(margin=0.05)\n    \n    minimum = np.argsort(np.array([AUC0a, AUC1a, AUC2a, AUC3a, AUC]))[0]\n    # print(minimum)\n    \n    if minimum == 0:\n        index0p = []\n        for i in group0p:\n            index0p.extend([i]*len(groupn))\n        index0an = (groupn)*len(group0p)\n        # print (index0p, index0an)\n        return loss(torch.index_select(outputs,0,torch.tensor(index0p).to(device)), torch.index_select(outputs,0,torch.tensor(index0an).to(device)), (torch.ones(len(index0p),1)*1).to(device))\n    \n    elif minimum == 1:\n        index1p = []\n        for i in group1p:\n            index1p.extend([i]*len(groupn))\n        index1an = (groupn)*len(group1p)\n        \n        return loss(torch.index_select(outputs,0,torch.tensor(index1p).to(device)), torch.index_select(outputs,0,torch.tensor(index1an).to(device)), (torch.ones(len(index1p),1)*1).to(device))\n\n\n    elif minimum == 2:\n        index2p = []\n        for i in group2p:\n            index2p.extend([i]*len(groupn))\n        index2an = (groupn)*len(group2p)\n        \n        return loss(torch.index_select(outputs,0,torch.tensor(index2p).to(device)), torch.index_select(outputs,0,torch.tensor(index2an).to(device)), (torch.ones(len(index2p),1)*2).to(device))\n    \n    elif minimum == 3:\n        index3p = []\n        for i in group3p:\n            index3p.extend([i]*len(groupn))\n        index3an = (groupn)*len(group3p)\n        \n        return loss(torch.index_select(outputs,0,torch.tensor(index3p).to(device)), torch.index_select(outputs,0,torch.tensor(index3an).to(device)), (torch.ones(len(index3p),1)*1).to(device))    \n    \n    else:\n        indexp = []\n        for i in groupp:\n            indexp.extend([i]*len(groupn))\n        indexn = (groupn)*len(groupp)\n        \n        return loss(torch.index_select(outputs,0,torch.tensor(indexp).to(device)), torch.index_select(outputs,0,torch.tensor(indexn).to(device)), (torch.ones(len(indexp),1)*1).to(device))\n\n\n# def train_model(dataloaders,model, criterion, optimizer, scheduler, num_epochs=25):\ndef train_model(dataloaders, filename, model, criterion, optimizer, num_epochs=25):\n    since = time.time()\n    fopen = open(filename, \"w\")\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_AUROC_avg = 0.0\n    losses = Counter()\n    \n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 100)\n        \n        \n        \n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            gt = torch.FloatTensor().to(device)\n            pred = torch.FloatTensor().to(device)\n            losses.reset()\n            groups = []\n            \n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n            \n            # Iterate over data.\n            t = tqdm(enumerate(dataloaders[phase]),  desc='Loss: **** ', total=len(dataloaders[phase]), bar_format='{desc}{bar}{r_bar}')\n            for batch_idx, (inputs, labels, group) in t:\n                # if batch_idx == 0:\n                #     continue\n                # print(torch.isnan(inputs).sum())\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                #print(inputs.shape, labels.shape)\n                # print('the lables is',torch.unique(labels))\n                if len(torch.unique(labels)) !=1 and len(np.unique(group) != 1):\n                    # print(len(torch.unique(labels)))\n                    # zero the parameter gradients\n                    optimizer.zero_grad()\n\n                    # forward\n                    # track history if only in train\n                    with torch.set_grad_enabled(phase == 'train'):\n                        outputs = model(inputs)\n\n                        gt = torch.cat((gt, labels), 0)\n                        pred = torch.cat((pred, outputs.data), 0)\n                        groups += group\n\n                        # print('outputs shape',outputs.shape)\n                        # print('labels shape', labels.shape)\n                        # print('groups shape', group.shape)\n                        loss = criterion(outputs, labels, group)\n\n                        # backward + optimize only if in training phase\n                        if phase == 'train':\n                            loss.backward()\n                            optimizer.step()\n\n                    # statistics\n                    losses.update(loss.data.item(), inputs.size(0))\n                    t.set_description('Loss: %.3f ' % (losses.avg))\n            \n            AUCs = compute_AUCs(gt, pred)\n            AUROC_avg = AUCs\n            AUC, A00, A11, A22, A33, A0a, A1a, A2a, A3a, Aa0, Aa1, Aa2, Aa3, group_num = group_auc(gt, pred, groups)\n            \n            if phase == \"val\":\n                \n                # scheduler.step(losses.avg)\n                \n                if best_AUROC_avg < AUROC_avg:\n                    best_AUROC_avg = AUROC_avg\n                    torch.save(model.state_dict(), \"/prj0129/mil4012/glaucoma/NIH-chest-x-ray/CXR8/weights/densenet201_mimic_gender_age_nofinding4.pth\")\n                fopen.write('\\nEpoch {} \\t [{}] : \\t {AUROC_avg:.3f}\\n'.format(epoch, phase, AUROC_avg=AUROC_avg))\n                fopen.write('{} \\t {}\\n'.format(CLASS_NAMES, AUCs))\n                fopen.write('-' * 100)\n                    \n            print('Epoch: [{0}][{1}/{2}]\\t'\n                  'Loss {loss.val:.4f} ({loss.avg:.4f})'.format(\n                   epoch, batch_idx + 1, len(dataloaders[phase]), loss=losses))\n            print('{} : \\t {AUROC_avg:.3f}'.format(phase, AUROC_avg=AUROC_avg))\n            print('AUC',AUC)\n            print('A00',A00)\n            print('A11',A11)\n            print('A22',A22)\n            print('A33',A33)\n            print('A0a',A0a)\n            print('A1a',A1a)\n            print('A2a',A2a)\n            print('A3a',A3a)\n            print('Aa0',Aa0)\n            print('Aa1',Aa1)\n            print('Aa2',Aa2)\n            print('Aa3',Aa3)\n            print('Group Num',group_num)\n            \n            fopen.flush()\n    fopen.close()\n    return model\n\n\ndef test_model(test_loader,model):\n    model.eval()\n    gt = torch.FloatTensor().to(device)\n    pred = torch.FloatTensor().to(device)\n    groups = []\n    with torch.no_grad():\n        for batch_idx, (inputs, labels, group) in enumerate(test_loader):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model(inputs)\n            gt = torch.cat((gt, labels), 0)\n            pred = torch.cat((pred, outputs.data), 0)\n            groups += group\n    AUCs = compute_AUCs(gt, pred)\n    AUC, A00, A11, A22, A33, A0a, A1a, A2a, A3a, Aa0, Aa1, Aa2, Aa3, group_num = group_auc(gt, pred, groups)\n    print('AUCs',AUCs)\n    print('AUC',AUC)\n    print('A00',A00)\n    print('A11',A11)\n    print('A22',A22)\n    print('A33',A33)\n    print('A0a',A0a)\n    print('A1a',A1a)\n    print('A2a',A2a)\n    print('A3a',A3a)\n    print('Aa0',Aa0)\n    print('Aa1',Aa1)\n    print('Aa2',Aa2)\n    print('Aa3',Aa3)\n    print('Group Num',group_num)\n    pred1 = pred.cpu()\n    pred2 = pred1.numpy()\n    gt1 = gt.cpu()\n    gt2 = gt1.numpy()\n#     groups1 = groups.cpu()\n#     groups2 = groups1.numpy\n    np.savez('/prj0129/mil4012/glaucoma/NIH-chest-x-ray/CXR8/Result/densenet201_mimic_gender_age_nofinding4.npz', prediction=pred2, label=gt2, group=groups) \n    np.savetxt('/prj0129/mil4012/glaucoma/NIH-chest-x-ray/CXR8/Result/densenet201_mimic_gender_age_nofinding4.txt', pred2)     \n\nif __name__ == '__main__':\n    \n    train_sampler = None\n    batch_size = 96\n    workers = 4\n    N_CLASSES = 1\n    CLASS_NAMES = 'MIMIC'\n    \n\n    #get data and label for training, validate, and testing dataset.\n    \n    #training dataset\n    tmp = np.loadtxt(image_path_train, dtype=np.str, delimiter=\",\")\n    train_path = tmp[:,0]\n    train_path = train_path[1:len(train_path)]\n    # train_path = train_path[1:2000]\n    #7-> lung lesion, 12->pneumonia, 13->pneumothorax, 9->no finding, 16->gender, 17->age, 18->race\n    labels = tmp[:,9]\n    print('the disease is',labels[0])\n    labels = labels[1:len(labels)]  \n    # labels = labels[1:2000]\n    gender = tmp[:,16]\n    gender = gender[1:len(gender)]\n    \n    age = tmp[:,17]\n    age = age[1:len(age)]\n    \n    race = tmp[:,18]\n    race = race[1:len(race)]\n    \n    \n    train_label = copy.deepcopy(labels)\n    ind = np.argwhere(labels=='1.0')\n    train_label[ind] = 1\n    ind = np.argwhere(labels!='1.0')\n    train_label[ind] = 0\n    train_label = np.asarray(train_label, dtype=int)\n    \n    ##gender and age\n    train_groups = copy.deepcopy(gender)\n    age = np.asarray(age, dtype=float)\n    ind = np.argwhere(gender=='M')\n    ind1 = np.argwhere(age < 60)\n    ind2 = np.intersect1d(ind, ind1)\n    train_groups[ind2] = 0\n    \n    ind = np.argwhere(gender=='M')\n    ind1 = np.argwhere(age >= 60)\n    ind2 = np.intersect1d(ind, ind1)\n    train_groups[ind2] = 1\n    \n    ind = np.argwhere(gender=='F')\n    ind1 = np.argwhere(age < 60)\n    ind2 = np.intersect1d(ind, ind1)\n    train_groups[ind2] = 2\n    \n    ind = np.argwhere(gender=='F')\n    ind1 = np.argwhere(age >= 60)\n    ind2 = np.intersect1d(ind, ind1)\n    train_groups[ind2] = 3\n    train_groups = np.asarray(train_groups, dtype=int)\n    \n    \n    #val dataset\n    tmp = np.loadtxt(image_path_val, dtype=np.str, delimiter=\",\")\n    val_path = tmp[:,0]\n    val_path = val_path[1:len(val_path)]\n    #7-> lung lesion, 12->pneumonia, 13->pneumothorax, 9->no finding, 16->gender, 17->age, 18->race\n    labels = tmp[:,9]\n    print('the disease is',labels[0])\n    labels = labels[1:len(labels)]  \n    \n    gender = tmp[:,16]\n    gender = gender[1:len(gender)]\n    \n    age = tmp[:,17]\n    age = age[1:len(age)]\n    \n    race = tmp[:,18]\n    race = race[1:len(race)]\n    \n    \n    val_label = copy.deepcopy(labels)\n    ind = np.argwhere(labels=='1.0')\n    val_label[ind] = 1\n    ind = np.argwhere(labels!='1.0')\n    val_label[ind] = 0\n    val_label = np.asarray(val_label, dtype=int)\n    \n    \n    ##gender and age\n    val_groups = copy.deepcopy(gender)\n    age = np.asarray(age, dtype=float)\n    ind = np.argwhere(gender=='M')\n    ind1 = np.argwhere(age < 60)\n    ind2 = np.intersect1d(ind, ind1)\n    val_groups[ind2] = 0\n    \n    ind = np.argwhere(gender=='M')\n    ind1 = np.argwhere(age >= 60)\n    ind2 = np.intersect1d(ind, ind1)\n    val_groups[ind2] = 1\n    \n    ind = np.argwhere(gender=='F')\n    ind1 = np.argwhere(age < 60)\n    ind2 = np.intersect1d(ind, ind1)\n    val_groups[ind2] = 2\n    \n    ind = np.argwhere(gender=='F')\n    ind1 = np.argwhere(age >= 60)\n    ind2 = np.intersect1d(ind, ind1)\n    val_groups[ind2] = 3  \n\n    \n    val_groups = np.asarray(val_groups, dtype=int)\n        \n    #test dataset\n    tmp = np.loadtxt(image_path_test, dtype=np.str, delimiter=\",\")\n    test_path = tmp[:,0]\n    test_path = test_path[1:len(test_path)]\n    #7-> lung lesion, 12->pneumonia, 13->pneumothorax, 9->no finding, 16->gender, 17->age, 18->race\n    labels = tmp[:,9]\n    print('the disease is',labels[0])\n    labels = labels[1:len(labels)]  \n    \n    gender = tmp[:,16]\n    gender = gender[1:len(gender)]\n    \n    age = tmp[:,17]\n    age = age[1:len(age)]\n    \n    race = tmp[:,18]\n    race = race[1:len(race)]\n    \n\n    test_label = copy.deepcopy(labels)\n    ind = np.argwhere(labels=='1.0')\n    test_label[ind] = 1\n    ind = np.argwhere(labels!='1.0')\n    test_label[ind] = 0\n    test_label = np.asarray(test_label, dtype=int)\n    \n    \n    ##gender and age\n    test_groups = copy.deepcopy(gender)\n    age = np.asarray(age, dtype=float)\n    ind = np.argwhere(gender=='M')\n    ind1 = np.argwhere(age < 60)\n    ind2 = np.intersect1d(ind, ind1)\n    test_groups[ind2] = 0\n    \n    ind = np.argwhere(gender=='M')\n    ind1 = np.argwhere(age >= 60)\n    ind2 = np.intersect1d(ind, ind1)\n    test_groups[ind2] = 1\n    \n    ind = np.argwhere(gender=='F')\n    ind1 = np.argwhere(age < 60)\n    ind2 = np.intersect1d(ind, ind1)\n    test_groups[ind2] = 2\n    \n    ind = np.argwhere(gender=='F')\n    ind1 = np.argwhere(age >= 60)\n    ind2 = np.intersect1d(ind, ind1)\n    test_groups[ind2] = 3\n    \n    \n    \n\n    test_groups = np.asarray(test_groups, dtype=int)\n                        \n    train_label = train_label.astype(np.float)\n    val_label = val_label.astype(np.float) \n    test_label = test_label.astype(np.float) \n    \n    train_label = np.reshape(train_label,(len(train_label),1)) \n    val_label = np.reshape(val_label,(len(val_label),1)) \n    test_label = np.reshape(test_label,(len(test_label),1)) \n    \n    \n\n    \n    data_transforms = {\n        'train': transforms.Compose([\n            transforms.RandomRotation(10),\n            # transforms.ToPILImage(),\n            transforms.Resize(224),\n            # transforms.CenterCrop(224),\n            transforms.RandomHorizontalFlip(0.5),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ]),\n        'val': transforms.Compose([\n            transforms.Resize(224),\n            # transforms.CenterCrop(224),\n            # transforms.ToPILImage(),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ]),\n    }\n    \n    train_dataset = Dataset(train_path,train_label,groups=train_groups,transform = data_transforms[\"train\"])\n    val_dataset = Dataset(val_path,val_label,groups=val_groups,transform = data_transforms[\"val\"])\n    test_dataset = Dataset(test_path,test_label,groups=test_groups,transform = data_transforms[\"val\"])\n    \n    \n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=(train_sampler is None), \n                                           num_workers=workers, pin_memory=True, sampler=train_sampler)\n\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=(train_sampler is None), \n                                           num_workers=workers, pin_memory=True, sampler=train_sampler)\n    \n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, \n                                           num_workers=workers, pin_memory=True, sampler=train_sampler)\n\n    dataloaders = {\"train\": train_loader, \"val\": val_loader}\n    \n    model_ft = models.densenet201(pretrained=True)\n    num_ftrs = model_ft.classifier.in_features\n    model_ft.classifier = nn.Sequential(\n                nn.Linear(num_ftrs, N_CLASSES),\n                nn.Sigmoid()\n            )\n    model_ft = model_ft.to(device)\n    \n    optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.00005)\n    \n    # optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n    \n    # Decay LR by a factor of 0.1 every 7 epochs\n#     exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, 'min', patience=2, eps=1e-08, verbose=True)\n\n    # model_ft = train_model(dataloaders, model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n    #                        num_epochs=20)\n    model_ft = train_model(dataloaders, model_ft, criterion, optimizer_ft,num_epochs=20)\n    model_ft.load_state_dict(torch.load(\"/prj0129/mil4012/glaucoma/NIH-chest-x-ray/CXR8/weights/densenet201_mimic_gender_age_nofinding4.pth\"))\n    test_model(test_loader,model_ft)","metadata":{},"execution_count":null,"outputs":[]}]}